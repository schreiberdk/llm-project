{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07f56df5-167c-4a04-868f-6709933ae037",
   "metadata": {},
   "source": [
    "# Try some LLM models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f07b42-af03-4a2b-90f5-d7936f2e8dfe",
   "metadata": {},
   "source": [
    "## TinyLlama/TinyLlama-1.1B-Chat-v1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4eacb33-2100-402b-93d4-f4cfe8c8a68e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T15:45:02.288586Z",
     "iopub.status.busy": "2025-07-17T15:45:02.287867Z",
     "iopub.status.idle": "2025-07-17T15:45:02.291665Z",
     "shell.execute_reply": "2025-07-17T15:45:02.290834Z",
     "shell.execute_reply.started": "2025-07-17T15:45:02.288567Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbed745-bef6-489d-baef-acff931a26ae",
   "metadata": {},
   "source": [
    "Check for GPU compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b15a772-daa0-45d5-86aa-49246a36856d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T15:45:03.379711Z",
     "iopub.status.busy": "2025-07-17T15:45:03.378976Z",
     "iopub.status.idle": "2025-07-17T15:45:03.383516Z",
     "shell.execute_reply": "2025-07-17T15:45:03.382842Z",
     "shell.execute_reply.started": "2025-07-17T15:45:03.379692Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n",
      "True\n",
      "NVIDIA GeForce RTX 4070 SUPER\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daf1f4ea-53cb-41ad-b4d1-98a7c6b5307d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T14:41:23.552504Z",
     "iopub.status.busy": "2025-07-17T14:41:23.552286Z",
     "iopub.status.idle": "2025-07-17T14:41:23.679957Z",
     "shell.execute_reply": "2025-07-17T14:41:23.679222Z",
     "shell.execute_reply.started": "2025-07-17T14:41:23.552489Z"
    }
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "with open(\"../.huggingfacetoken.txt\", \"r\") as f:\n",
    "    token = f.read().strip()\n",
    "    \n",
    "login(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bb4102-d5c3-4b9d-a5a1-3356b2ce7f01",
   "metadata": {},
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa7cf47f-b79f-424d-b952-b60e243061cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T15:45:04.490282Z",
     "iopub.status.busy": "2025-07-17T15:45:04.489827Z",
     "iopub.status.idle": "2025-07-17T15:45:05.344998Z",
     "shell.execute_reply": "2025-07-17T15:45:05.344278Z",
     "shell.execute_reply.started": "2025-07-17T15:45:04.490265Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "device = \"cuda\"                     # or \"cuda:0\"\n",
    "\n",
    "model_path = \"../models/TinyLlama\"           # relative or absolute\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "model     = AutoModelForCausalLM.from_pretrained(\n",
    "               model_path,\n",
    "               torch_dtype=torch.float16,\n",
    "               device_map=device\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a3436b0-e057-4d70-9a77-c701be935521",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T15:45:06.041086Z",
     "iopub.status.busy": "2025-07-17T15:45:06.040432Z",
     "iopub.status.idle": "2025-07-17T15:45:11.501856Z",
     "shell.execute_reply": "2025-07-17T15:45:11.501215Z",
     "shell.execute_reply.started": "2025-07-17T15:45:06.041070Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Human: Explain black holes in 2–3 sentences.\n",
      "### Assistant: Black holes are regions of space-time where gravity is so strong that it can crush matter into a singularity, leaving behind nothing but empty space and an enormous amount of energy. They are named after the dark, mysterious and mysterious objects they resemble, which form when massive stars collapse under their own gravity. The intense gravitational forces created by these collapsed stars create a black hole, which has no escape from its gravitational pull. When a star becomes a black hole, it gradually begins to consume more and more matter, eventually shrinking to a point where it becomes indistinguishable from the surrounding gas and dust. This process is called accretion, which means \"to gather\" or \"to grow.\" Once a black hole has attained enough mass, it can start to emit radiation, known as Hawking radiation, which can be detected by telescopes on Earth. However, it's believed that this radiation is so weak that it doesn't pose any significant threat to the universe.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"### Human: Explain black holes in 2–3 sentences.\\n### Assistant:\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=512,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    do_sample=True,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "    repetition_penalty=1.1\n",
    ")\n",
    "\n",
    "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(response)\n",
    "\n",
    "if not response.strip().endswith((\".\", \"!\", \"?\", \"”\", \"\\\"\")):\n",
    "    print(\"⚠️ Likely cut off — consider increasing max_new_tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208811af-57b4-44bc-be6e-a4f6977a54d9",
   "metadata": {},
   "source": [
    "## Run on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c1d29f5d-d135-4480-b6a5-119031194073",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T14:18:48.851401Z",
     "iopub.status.busy": "2025-06-25T14:18:48.850850Z",
     "iopub.status.idle": "2025-06-25T14:19:01.494723Z",
     "shell.execute_reply": "2025-06-25T14:19:01.494036Z",
     "shell.execute_reply.started": "2025-06-25T14:18:48.851382Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Human: What is quantum entanglement?\n",
      "### Assistant: Quantum entanglement is a phenomenon where two particles, such as photons or electrons, become connected in such a way that their states are correlated even when separated by great distances. This means that the state of one particle can be predicted with certainty from the state of the other particle, even if they are not directly connected. This is a fundamental property of quantum mechanics and has\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
    "    torch_dtype=torch.float32,      # fp16 won’t work on pure CPU\n",
    "    device_map=device\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\n",
    "\n",
    "prompt = \"### Human: What is quantum entanglement?\\n### Assistant:\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)   # SAME device\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens=80)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d839ce28-858a-41cb-853e-20806c1df558",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
