{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07f56df5-167c-4a04-868f-6709933ae037",
   "metadata": {},
   "source": [
    "# Try some LLM models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f07b42-af03-4a2b-90f5-d7936f2e8dfe",
   "metadata": {},
   "source": [
    "## TinyLlama/TinyLlama-1.1B-Chat-v1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4eacb33-2100-402b-93d4-f4cfe8c8a68e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T14:12:48.245295Z",
     "iopub.status.busy": "2025-06-25T14:12:48.244765Z",
     "iopub.status.idle": "2025-06-25T14:12:48.248320Z",
     "shell.execute_reply": "2025-06-25T14:12:48.247625Z",
     "shell.execute_reply.started": "2025-06-25T14:12:48.245279Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbed745-bef6-489d-baef-acff931a26ae",
   "metadata": {},
   "source": [
    "Check for GPU compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b15a772-daa0-45d5-86aa-49246a36856d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T14:12:50.823234Z",
     "iopub.status.busy": "2025-06-25T14:12:50.822615Z",
     "iopub.status.idle": "2025-06-25T14:12:50.827148Z",
     "shell.execute_reply": "2025-06-25T14:12:50.826480Z",
     "shell.execute_reply.started": "2025-06-25T14:12:50.823218Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n",
      "True\n",
      "NVIDIA GeForce RTX 4070 SUPER\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daf1f4ea-53cb-41ad-b4d1-98a7c6b5307d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T14:12:51.618143Z",
     "iopub.status.busy": "2025-06-25T14:12:51.617601Z",
     "iopub.status.idle": "2025-06-25T14:12:51.824439Z",
     "shell.execute_reply": "2025-06-25T14:12:51.823753Z",
     "shell.execute_reply.started": "2025-06-25T14:12:51.618122Z"
    }
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "with open(\"../.huggingfacetoken.txt\", \"r\") as f:\n",
    "    token = f.read().strip()\n",
    "    \n",
    "login(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bb4102-d5c3-4b9d-a5a1-3356b2ce7f01",
   "metadata": {},
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa7cf47f-b79f-424d-b952-b60e243061cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T14:24:41.682274Z",
     "iopub.status.busy": "2025-06-25T14:24:41.681352Z",
     "iopub.status.idle": "2025-06-25T14:24:42.839188Z",
     "shell.execute_reply": "2025-06-25T14:24:42.838515Z",
     "shell.execute_reply.started": "2025-06-25T14:24:41.682249Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "device = \"cuda\"                     # or \"cuda:0\"\n",
    "\n",
    "model_path = \"../models/TinyLlama\"           # relative or absolute\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "model     = AutoModelForCausalLM.from_pretrained(\n",
    "               model_path,\n",
    "               torch_dtype=torch.float16,\n",
    "               device_map=device\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4a3436b0-e057-4d70-9a77-c701be935521",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T14:27:34.055869Z",
     "iopub.status.busy": "2025-06-25T14:27:34.055527Z",
     "iopub.status.idle": "2025-06-25T14:27:37.381581Z",
     "shell.execute_reply": "2025-06-25T14:27:37.380846Z",
     "shell.execute_reply.started": "2025-06-25T14:27:34.055852Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Human: Explain black holes in 2–3 sentences.\n",
      "### Assistant: A black hole is a region of space where gravity has become so strong that nothing, not even light, can escape from its gravitational pull. As a result, it has an intense and singular shape, with a point at one end and a swirling mass of material at the other. Black holes are often associated with supermassive stars or neutron stars, which emit radiation and produce magnetic fields that make them attracted to each other. In this way, they form their own neighborhoods within the galaxy.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"### Human: Explain black holes in 2–3 sentences.\\n### Assistant:\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=512,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    do_sample=True,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "    repetition_penalty=1.1\n",
    ")\n",
    "\n",
    "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(response)\n",
    "\n",
    "if not response.strip().endswith((\".\", \"!\", \"?\", \"”\", \"\\\"\")):\n",
    "    print(\"⚠️ Likely cut off — consider increasing max_new_tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208811af-57b4-44bc-be6e-a4f6977a54d9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Run on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c1d29f5d-d135-4480-b6a5-119031194073",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-25T14:18:48.851401Z",
     "iopub.status.busy": "2025-06-25T14:18:48.850850Z",
     "iopub.status.idle": "2025-06-25T14:19:01.494723Z",
     "shell.execute_reply": "2025-06-25T14:19:01.494036Z",
     "shell.execute_reply.started": "2025-06-25T14:18:48.851382Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Human: What is quantum entanglement?\n",
      "### Assistant: Quantum entanglement is a phenomenon where two particles, such as photons or electrons, become connected in such a way that their states are correlated even when separated by great distances. This means that the state of one particle can be predicted with certainty from the state of the other particle, even if they are not directly connected. This is a fundamental property of quantum mechanics and has\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
    "    torch_dtype=torch.float32,      # fp16 won’t work on pure CPU\n",
    "    device_map=device\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\n",
    "\n",
    "prompt = \"### Human: What is quantum entanglement?\\n### Assistant:\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)   # SAME device\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens=80)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d839ce28-858a-41cb-853e-20806c1df558",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
